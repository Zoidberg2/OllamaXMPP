[credentials]
jid = bot@example.com
password = Password

[users]
allowed_users = user1@example.com/resource,user2@example.com/resource,user3@example.com/resource

[server]
llama_server_url = http://localhost:11434

[muc]
room = roomid@conference.example.com
nick = bot

[keys]
keypasswd = none
keys_directory = /path/to/keys
contacts_keys_directory = /path/to/contact_keys
public_key_file = public_key.asc

[llm]
model = deepseek-r1:7b
prompt = You are a very helpful assistant, you are a conversational AI model. You will be having a conversation with an user.
device = gpu
num_gpu = 1
num_thread = 8
batch_size = 32
quantization_mode = int8
cache_type = redis
cache_capacity = 10gb
compute_type = float16
tensor_parallel = True


    # [OMEMOStorage]
    # json_file = /path/to/omemo-echo-client.json
    
